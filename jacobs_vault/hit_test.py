# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/05_HitTest.ipynb (unless otherwise specified).

__all__ = ['COLUMNS', 'DTYPES', 'DATE_COLS', 'DAY_FILE_PATH', 'HitTest', 'test_skyfield', 'hit_quality', 'colorize',
           'QUALITY_COLORS', 'viz']

# Cell

# Requires modules in ../jacobs_vault be available. Either:
#    ln -s nbs/jacobs_vault -> jacobs_vault
# or:
#    in each notebook `import sys; sys.path.append('..')`
# or:
#    add .. to PYTHONPATH.

from .template import *   # currently just a config test

from datetime import datetime
from dateutil import tz
from skyfield.api import EarthSatellite
from skyfield.api import Topos, load
import math
import pandas as pd
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.graph_objects as go
import numpy as np

# Cell
COLUMNS = ["satellite", "day_dt", "day", "tle_dt", "tle_ts", "line1", "line2"]
# DTYPES = [str, str, int, str, int, str, str]
DTYPES = {'satellite': 'uint16', # observed values are ints in 5..41678, so 0..65535 is good
          'day_dt': 'str',       # here a single date, but generally datetime: PARSE
          'day': 'uint16',       # here a single value 6026, too big for uint8, but 16 is good
          'tle_dt': 'str',       # again, PARSE AS DATETIME
          'tle_ts': 'uint32',    # large ints, but < 4294967295. We could compress more, but... meh
          'line1': 'string',     # 12K unique 80-char TLE strings. Category wd give tiny compression.
          'line2': 'string'}     # In theory "string" is better than "object". Not seeing it here.

DATE_COLS = ['day_dt', 'tle_dt']

# Where to look for the TLE dayfiles.
# Symlink ../data to the actual data.
DAY_FILE_PATH="../data/VAULT_Data/TLE_daily"



# Cell

class HitTest:
    """ Counts the satellites that are visible at a given point on the globe at a
    given time, and returns counts classified by data quality and
    latitude, azimuth, hit_quality, radius for visible satellites
    """
    def __init__(self, dt, day_file_base_path=DAY_FILE_PATH):
        """Look for and load TLE datafile for {dt}."""
        df_path = "%s/%4d/%02d/%02d.tab.gz"%(day_file_base_path, dt.year, dt.month, dt.day)
        print(f"Trying to load {df_path}")
        df = pd.read_csv(df_path,
                         names=COLUMNS, sep='\t', compression='gzip',
                         dtype=DTYPES,
                         parse_dates=dates,
                         infer_datetime_format=True)
        self.df_day_tle = df.drop_duplicates()
    #


    def satellite_alt_az_days(self, _t0: datetime, lat: float, lon: float):
        '''Load tracks for day {_t0} and return altitiude, azimuth, and ðš«t [days]
        for each row.
        Usage eg: satellite_alt_az_days(datetime(2016, 6, 30), 45.0, -176.0)

        '''
        earth_position = Topos(lat, lon)

        ts = load.timescale()
        t = ts.utc(_t0.replace(tzinfo=tz.tzutc()))

        def eval_tle(row):
            '''Extract satellite info from line1/line2/tle_dt.

            Returns alt, az, and (days between dt and each row).
            Inherits {ts}, {t}, and {earth_position} values at function definition.

            TODO: Currently only works for `apply(raw=False)`.

            '''
            try:
                satellite = EarthSatellite(row['line1'], row['line2'], 'x', ts)
                ðš«t = abs(_t0 - row['tle_dt']).days
            except IndexError:
                # `apply(raw=True)` sends arrays instead of Series
                satellite = EarthSatellite(row[5], row[6], 'x', ts)
                ðš«t = abs(_t0 - row[3]).days
            topocentric = (satellite - earth_position).at(t)
            alt, az, distance = topocentric.altaz()
            return pd.Series([alt.degrees, az.degrees, ðš«t])

        df = load_day_file(_t0).drop_duplicates()
        df_alt_az_days = pd.DataFrame(df.apply(eval_tle, axis=1, raw=False))
        df_alt_az_days.columns = ["altitude", "azimuth", "days"]
        #df_alt_az_days.reindex()
        return df_alt_az_days


    def invoke(self, dt, lat, lon):
        ''' Main logic for satellite hit-testing service

            returns 2 DataFrames:
             - df_hit_miss_table :       The hit,miss stats table
             - df_alt_az_days_visible :  The information on the visible satellites for star-map plotting
        '''
        df_alt_az_days = self.satellite_alt_az_days(dt, lat, lon)

        # "invert" altitude for polar plotting.  Doing this thousands of times
        #  more than necessary (really just want R for the df_alt_az_days_visible slice)
        #  but pandas does not like apply on a slice.
        df_alt_az_days.loc["R"] = 90.0 - df_alt_az_days["altitude"]

        def apply_quality_str(row, col):
            q = ""
            if row[col] == QUALITY_EXCELLENT:
                q = "Excellent"
            elif row[col] == QUALITY_GOOD:
                q = "Good"
            elif row[col] == QUALITY_POOR:
                q = "Poor"
            elif row[col] == QUALITY_STALE:
                q = "Stale"
            # no-else ... leave the NaNs alone
            return q
        #

        df_hit_miss_table = pd.concat([
                df_alt_az_days.apply(partial(apply_quality_str, col="hit"), axis=1).value_counts(),
                df_alt_az_days.apply(partial(apply_quality_str, col="miss"), axis=1).value_counts()]
            , axis=1, sort=False)

        df_alt_az_days_visible = df_alt_az_days[df_alt_az_days["altitude"]>0]

        return df_hit_miss_table, df_alt_az_days_visible
    #

    def web_invoke(self, dt, lat, lon):
        ''' Main support function for satellite hit-testing service

            returns a json object having two objects:
            {
                "hitmiss": The hit,miss stats table
                "visible": The information on the visible satellites
            }
        '''
        df_hit_miss_table, df_alt_az_days_visible = self.invoke(dt, lat, lon)
        result = {
            "hitmiss": df_hit_miss_table.to_dict(),
            "visible": df_alt_az_days_visible.to_dict()
        }
        return json.dumps(result)
    #


# Cell
def test_skyfield():
    lat =  45.0
    lon = -176.0
    earth_position = Topos(lat, lon)

    ts = load.timescale()
    t = ts.utc(datetime(2016, 6, 30).replace(tzinfo=tz.tzutc()))

    line1="1 10000U 77034A   16182.45131225 -.00000171  00000-0  00000+0 0  1275"
    line2="2 10000  15.5820 331.7785 0019081 259.0540  28.2803  0.96674507130362"
    satellite = EarthSatellite(line1, line2, '77034', ts)

    difference = satellite - earth_position

    topocentric = difference.at(t)
    alt, az, distance = topocentric.altaz()

    print(f'{alt.degrees:.1f}Âº, {az.degrees:.1f}Âº, {distance.km:.1f}km')
#
test_skyfield()

# Cell


# Cell

def hit_quality(df_alt_az_days, MISS=0,
               EXC=2., GOOD=14., POOR=56.):
    """Return hit/miss and quality as time proximity.

    Parameters
    ----------
    `df_alt_az_days`: Dataframe returned by `satellite_alt_az_days`.
    `MISS`: Alt. < MISS is a miss. (Default=0, the horizon)
    `EXC`: TLE age less than this is 'excellent' (Default 2)
    `GOOD`: TLE age less than this is 'good' (Default 14)
    `POOR`: TLE age less than this is 'poor' (Default 56)
            Anything older is 'stale'.

    Returns
    --------
    Dataframe with columns ["hit", "miss"]. Each row will have exactly one filled, with
    a string denoting how recent the pass was, e.g. "excellent", "good", "poor", "stale".

    """

    def eval_quality(row):
        """Inner function to be `apply`d to a dataframe."""
        ser = None
        days = row[2].days
        altitude = row[0]
        if days <= EXC:
            if altitude > MISS:
                vals = ["excellent", math.nan]
            else:
                vals = [math.nan, "excellent"]
        elif days <= GOOD:
            if altitude > MISS:
                vals = ["good", math.nan]
            else:
                vals = [math.nan, "good"]
        elif days <= POOR:
            if altitude > MISS:
                vals = ["poor", math.nan]
            else:
                vals = [math.nan, "poor"]
        else:
            vals = [math.nan, "stale"]

        return pd.Series(vals)

    df_hit_quality = pd.DataFrame(df_alt_az_days.apply(eval_quality, axis=1))
    df_hit_quality.columns = ["hit", "miss"]
    return df_hit_quality
#

# Cell

# These numbers may seem upside down,
# but I like the default coloring in the polar plot
# when hit quality has these values.
QUALITY_COLORS = {
    'excellent': 0,
    'good': 1,
    'poor': 2,
    'stale': 3
}

def colorize(df):
    """Replace quality strings with color numbers."""
    for k,v in QUALITY_COLORS.items():
        df.replace(k,v)


# Cell
def viz(df, show=True, size0=1):
    """Polar plots a `df_alt_az_days_visible` dataframe.
    Dataframe must have: `color`, `days`, `altitude`, `azimuth`.
    Returns a Plotly Express polar plot figure.
    If show=True, also displays it here.
    size0 is the smallest marker size (used for best hits)

    """
    df["color"] = colorize()
    df.loc[(df["days"].dt.days <= 14.0), "color"] = 1
    df.loc[(df["days"].dt.days <= 2.0), "color"] = 0
    df["size"] = size0 + df["color"]*2
    df["R"] = 90.0 - df["altitude"]
    #fig = px.scatter_polar(df_alt_az_days_visible, r="R", theta="azimuth", color_discrete_sequence=['black'])
    fig = px.scatter_polar(df_alt_az_days_visible, r="R", theta="azimuth",
                           color="color", size="size", size_max=10, render_mode='webgl')
    if show:
        fig.update_traces(opacity=.5).show()
    return fig